{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "import sklearn.neighbors\n",
    "\n",
    "# constants\n",
    "RAW_DATA_PATH = 'raw_data'\n",
    "DATAFRAME_PATH = 'dataframes'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the playlists dataframe from raw JSON data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:04<00:00,  2.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing h5 files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:2434: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->Index(['name', 'collaborative', 'description'], dtype='object')]\n",
      "\n",
      "  pytables.to_hdf(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored files as h5\n"
     ]
    }
   ],
   "source": [
    "def make_playlist_dfs(path):\n",
    "    playlists = []\n",
    "    playlist_tracks = []\n",
    "    for file in tqdm(os.listdir(path)):\n",
    "        if not file.endswith(\".json\"):\n",
    "            continue\n",
    "        with open(f'{path}/{file}') as f:\n",
    "            js_slice = json.load(f)\n",
    "            for playlist in js_slice['playlists']:\n",
    "                for track in playlist['tracks']:\n",
    "                    playlist_tracks.append([track['track_uri'], playlist['pid'], track['pos']])\n",
    "                playlist.pop('tracks')\n",
    "                playlists.append(playlist)\n",
    "    playlists_df = pd.DataFrame(playlists)\n",
    "    playlist_tracks_df = pd.DataFrame(playlist_tracks, columns=['track_uri', 'pid', 'pos'])\n",
    "    playlist_tracks_df.set_index('pid')\n",
    "    print('Storing h5 files...')\n",
    "    playlists_df.to_hdf(DATAFRAME_PATH + '/playlists.h5', 'playlists')\n",
    "    playlist_tracks_df.to_hdf(DATAFRAME_PATH + '/playlist_tracks.h5', 'playlist_tracks')\n",
    "    print('Stored files as h5')\n",
    "\n",
    "make_playlist_dfs(RAW_DATA_PATH);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the playlists, tracks and track_info dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists_df = pd.read_hdf(DATAFRAME_PATH + '/playlists.h5', 'playlists')\n",
    "playlist_tracks_df = pd.read_hdf(DATAFRAME_PATH + '/playlist_tracks.h5', 'playlist_tracks')\n",
    "tracks_df = pd.read_hdf(DATAFRAME_PATH + '/tracks.h5', 'tracks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_playlists, test_playlists = train_test_split(playlists_df, test_size=0.2)\n",
    "\n",
    "# Modifying the test set\n",
    "train_playlist_tracks = playlist_tracks_df[playlist_tracks_df['pid'].isin(train_playlists['pid'].values)].reset_index(drop=True)\n",
    "test_playlist_tracks = playlist_tracks_df[playlist_tracks_df['pid'].isin(test_playlists['pid'].values)].reset_index(drop=True)\n",
    "\n",
    "train_tracks = tracks_df[tracks_df['track_uri'].isin(train_playlist_tracks['track_uri'].values)].drop_duplicates(subset=['track_uri'],ignore_index=True)\n",
    "test_tracks = tracks_df[tracks_df['track_uri'].isin(test_playlist_tracks['track_uri'].values)].drop_duplicates(subset=['track_uri'],ignore_index=True)\n",
    "\n",
    "# Keep only tracks that are in the training set in the test set\n",
    "def filter_playlist_tracks(all_tracks, tracks):\n",
    "    track_uris = pd.unique(all_tracks['track_uri'])\n",
    "    return tracks[tracks['track_uri'].isin(track_uris)].reset_index(drop=True)\n",
    "\n",
    "test_playlist_tracks_ground_truth = filter_playlist_tracks(train_playlist_tracks, test_playlist_tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some assertions on the ground truth set\n",
    "assert test_playlist_tracks_ground_truth[test_playlist_tracks_ground_truth['track_uri'].isin(train_tracks['track_uri']) == False].empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell can take long to run ~10mins\n",
    "# if .h5 files are available, use those\n",
    "def frac_to_sample(playlist_tracks):\n",
    "    if playlist_tracks.size >= 2:\n",
    "        return 0.5\n",
    "    else:\n",
    "        return None\n",
    "        \n",
    "def build_challenge_set():\n",
    "    challenge_set_list = []\n",
    "    new_test_set = []\n",
    "    for pid in tqdm(test_playlists['pid']):\n",
    "        playlist_tracks = test_playlist_tracks_ground_truth[test_playlist_tracks_ground_truth['pid'] == pid]\n",
    "        frac = frac_to_sample(playlist_tracks)\n",
    "        if frac is not None and frac > 0:\n",
    "            random_sample_df = playlist_tracks.sample(frac = frac, random_state=1)\n",
    "            num_sample = random_sample_df.size\n",
    "            new_test_set.append(test_playlists[test_playlists['pid'] == pid].values.flatten().tolist() + [num_sample, playlist_tracks.size-num_sample])\n",
    "            for index, track in random_sample_df.iterrows():\n",
    "                challenge_set_list.append([track['track_uri'], track['pid'], track['pos']])\n",
    "    _test = pd.DataFrame(new_test_set, columns=list(test_playlists.columns) + ['num_of_seeds', 'num_withheld'])\n",
    "    _tracks = pd.DataFrame(challenge_set_list, columns=list(test_playlist_tracks_ground_truth.columns))\n",
    "    return _test, _tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:08<00:00, 225.24it/s]\n",
      "D:\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:2434: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->Index(['name', 'collaborative', 'description'], dtype='object')]\n",
      "\n",
      "  pytables.to_hdf(\n"
     ]
    }
   ],
   "source": [
    "test_playlists_with_seed_info, test_tracks_incomplete = build_challenge_set()\n",
    "# Write challenge set as hdf\n",
    "test_playlists.to_hdf(DATAFRAME_PATH + '/test_playlists.h5', 'test_playlists')\n",
    "test_tracks_incomplete.to_hdf(DATAFRAME_PATH + '/test_tracks_incomplete.h5', 'test_tracks_incomplete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test dataframes\n",
    "test_playlists = pd.read_hdf(DATAFRAME_PATH + '/test_playlists.h5', 'test_playlists')\n",
    "test_tracks_incomplete = pd.read_hdf(DATAFRAME_PATH + '/test_tracks_incomplete.h5', 'test_tracks_incomplete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-8dda656bb8bf>:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  assert test_playlists[test_tracks_incomplete['pid'].isin(test_playlists['pid']) == False].empty\n",
      "<ipython-input-15-8dda656bb8bf>:3: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  assert test_playlists[test_tracks_incomplete['track_uri'].isin(train_tracks['track_uri']) == False].empty\n"
     ]
    }
   ],
   "source": [
    "# some assertions on the test set\n",
    "assert test_playlists[test_tracks_incomplete['pid'].isin(test_playlists['pid']) == False].empty\n",
    "assert test_playlists[test_tracks_incomplete['track_uri'].isin(train_tracks['track_uri']) == False].empty\n",
    "assert test_tracks_incomplete.size < test_playlist_tracks_ground_truth.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "NUM_NEIGHBORS = 10\n",
    "SELECTED_FEATURES = ['danceability', 'energy', 'key', 'loudness',\n",
    "                     'speechiness', 'acousticness', 'instrumentalness',\n",
    "                     'liveness', 'valence', 'tempo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_clf = sklearn.neighbors.NearestNeighbors(n_neighbors=NUM_NEIGHBORS)\n",
    "knn_clf.fit(train_tracks[SELECTED_FEATURES])\n",
    "distances, indices = knn_clf.kneighbors(test_tracks_incomplete[SELECTED_FEATURES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test_features.loc[0]\n",
    "#X_train_features.iloc[indices[0]].index\n",
    "test_idx = [0, 292891, 176330, 785063, 347886]\n",
    "X_train_features.reset_index().iloc[indices[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_challenge_set[X_challenge_set['pid'] == 106052]\n",
    "#X_test_track_info_ground_truth[X_test_track_info_ground_truth['pid'] == ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_features.iloc[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tracks_df = tracks_df.rename(columns={'tracks':'track_uri'})\n",
    "X_challenge_track_info_features = X_challenge_track_info.merge(tracks_df, how='outer', on='track_uri').dropna()\n",
    "X_challenge_track_info_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to read playlist from challenge set\n",
    "\n",
    "\n",
    "list_mean = []\n",
    "\n",
    "for _, playlist in X_challenge_set.iterrows():\n",
    "    tracks_with_features_in_playlist = X_challenge_track_info_features[X_challenge_track_info_features['pid'] == playlist['pid']]\n",
    "    mean = tracks_with_features_in_playlist[selected_features].mean()\n",
    "    mean['pid'] = playlist['pid']\n",
    "#     print(mean)\n",
    "    list_mean.append(mean)\n",
    "    # store for all pids\n",
    "    \n",
    "playlists_mean_features = pd.DataFrame(data=list_mean , columns=[*selected_features, 'pid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "distances, indices = knn_clf.kneighbors(tracks_with_features_in_playlist[selected_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(distances)\n",
    "print(indices)\n",
    "X_train_features.reset_index().iloc[indices[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances, indices = knn_clf.kneighbors(tracks_with_features_in_playlist[selected_features].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_with_features_in_playlist[selected_features].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_with_features_in_playlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlists_mean_features.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
