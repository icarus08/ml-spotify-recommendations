{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import sklearn\n",
    "import sklearn.neighbors\n",
    "from pathlib import Path\n",
    "from pandas.api.types import CategoricalDtype\n",
    "from operator import itemgetter\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# constants\n",
    "RAW_DATA_PATH = Path('raw_data/')\n",
    "DATAFRAME_PATH = Path('dataframes/')\n",
    "MODEL_PATH = Path('model/state_dict_model.pt')\n",
    "TOTAL_TRACKS = 50\n",
    "NUM_WITHHELD = 25\n",
    "N_NEIGHBORS = 25\n",
    "SELECTED_TRACK_FEATURES = ['danceability', 'energy', 'key', 'loudness',\n",
    "                     'speechiness', 'acousticness', 'instrumentalness',\n",
    "                     'liveness', 'valence', 'tempo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tid</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spotify:track:3uvsVUrAaGQJCTEUR1S3Sx</td>\n",
       "      <td>0.523</td>\n",
       "      <td>0.422</td>\n",
       "      <td>3</td>\n",
       "      <td>-10.385</td>\n",
       "      <td>0.0270</td>\n",
       "      <td>0.78300</td>\n",
       "      <td>0.005140</td>\n",
       "      <td>0.0898</td>\n",
       "      <td>0.145</td>\n",
       "      <td>129.876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spotify:track:0heE5tAAaDQmnGhVDImPl2</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.594</td>\n",
       "      <td>8</td>\n",
       "      <td>-4.404</td>\n",
       "      <td>0.0378</td>\n",
       "      <td>0.25600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0759</td>\n",
       "      <td>0.304</td>\n",
       "      <td>123.751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spotify:track:3omXshBamrREltcf24gYDC</td>\n",
       "      <td>0.468</td>\n",
       "      <td>0.692</td>\n",
       "      <td>2</td>\n",
       "      <td>-4.015</td>\n",
       "      <td>0.0295</td>\n",
       "      <td>0.02020</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.5230</td>\n",
       "      <td>0.561</td>\n",
       "      <td>78.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spotify:track:6TYWE19e35N7Bn5heHwyY6</td>\n",
       "      <td>0.553</td>\n",
       "      <td>0.564</td>\n",
       "      <td>9</td>\n",
       "      <td>-7.072</td>\n",
       "      <td>0.0418</td>\n",
       "      <td>0.03900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3180</td>\n",
       "      <td>0.310</td>\n",
       "      <td>149.953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spotify:track:1xznGGDReH1oQq0xzbwXa3</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.619</td>\n",
       "      <td>1</td>\n",
       "      <td>-5.886</td>\n",
       "      <td>0.0532</td>\n",
       "      <td>0.00784</td>\n",
       "      <td>0.004230</td>\n",
       "      <td>0.3510</td>\n",
       "      <td>0.371</td>\n",
       "      <td>103.989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    tid  danceability  energy  key  loudness  \\\n",
       "0  spotify:track:3uvsVUrAaGQJCTEUR1S3Sx         0.523   0.422    3   -10.385   \n",
       "1  spotify:track:0heE5tAAaDQmnGhVDImPl2         0.493   0.594    8    -4.404   \n",
       "2  spotify:track:3omXshBamrREltcf24gYDC         0.468   0.692    2    -4.015   \n",
       "3  spotify:track:6TYWE19e35N7Bn5heHwyY6         0.553   0.564    9    -7.072   \n",
       "4  spotify:track:1xznGGDReH1oQq0xzbwXa3         0.791   0.619    1    -5.886   \n",
       "\n",
       "   speechiness  acousticness  instrumentalness  liveness  valence    tempo  \n",
       "0       0.0270       0.78300          0.005140    0.0898    0.145  129.876  \n",
       "1       0.0378       0.25600          0.000000    0.0759    0.304  123.751  \n",
       "2       0.0295       0.02020          0.000002    0.5230    0.561   78.009  \n",
       "3       0.0418       0.03900          0.000000    0.3180    0.310  149.953  \n",
       "4       0.0532       0.00784          0.004230    0.3510    0.371  103.989  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read tracks.h5 which contains tracks with features like danceability, loudness ,... etc\n",
    "# set type of track_uri to category, to convert string to an int unique id\n",
    "# rename track_uri to tid and sort values based on tid\n",
    "tracks_features_df = pd.read_hdf(DATAFRAME_PATH / 'tracks.h5', 'tracks')\n",
    "cat_type = CategoricalDtype(categories=tracks_features_df.track_uri, ordered=True)\n",
    "tracks_features_df.track_uri = tracks_features_df.track_uri.astype(cat_type)\n",
    "tracks_features_df = tracks_features_df.rename(columns={'track_uri':'tid'})\n",
    "tracks_features_df = tracks_features_df[['tid',*SELECTED_TRACK_FEATURES]].sort_values('tid').reset_index(drop=True)\n",
    "tracks_features_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:02<00:00,  5.54it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tid</th>\n",
       "      <th>pid</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spotify:track:3uvsVUrAaGQJCTEUR1S3Sx</td>\n",
       "      <td>7000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spotify:track:0heE5tAAaDQmnGhVDImPl2</td>\n",
       "      <td>7000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spotify:track:3omXshBamrREltcf24gYDC</td>\n",
       "      <td>7000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spotify:track:6TYWE19e35N7Bn5heHwyY6</td>\n",
       "      <td>7000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spotify:track:1xznGGDReH1oQq0xzbwXa3</td>\n",
       "      <td>7000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    tid   pid  pos\n",
       "0  spotify:track:3uvsVUrAaGQJCTEUR1S3Sx  7000    0\n",
       "1  spotify:track:0heE5tAAaDQmnGhVDImPl2  7000    1\n",
       "2  spotify:track:3omXshBamrREltcf24gYDC  7000    2\n",
       "3  spotify:track:6TYWE19e35N7Bn5heHwyY6  7000    3\n",
       "4  spotify:track:1xznGGDReH1oQq0xzbwXa3  7000    4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read 10000 playlists from the official spoitfy 1M playlists\n",
    "# for each playlist, get the tracks and their positions\n",
    "def make_playlist_dfs(path):\n",
    "    playlists = []\n",
    "    playlist_tracks = []\n",
    "    for file in tqdm(os.listdir(path)):\n",
    "        if not file.endswith(\".json\"):\n",
    "            continue\n",
    "        with open(path/file) as f:\n",
    "            js_slice = json.load(f)\n",
    "            for playlist in js_slice['playlists']:\n",
    "                if playlist['num_tracks'] > TOTAL_TRACKS:\n",
    "                    sorted_tracks = sorted(playlist['tracks'], key=itemgetter('pos')) \n",
    "                    for track in sorted_tracks[:TOTAL_TRACKS]:\n",
    "                        yield track['track_uri'], playlist['pid'], track['pos']\n",
    "\n",
    "playlist_tracks_df = pd.DataFrame(make_playlist_dfs(RAW_DATA_PATH),columns=['tid','pid','pos'])\n",
    "playlist_tracks_df.tid = playlist_tracks_df.tid.astype(cat_type)\n",
    "playlist_tracks_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total playlists: 4907\n",
      "train playlists: 3925\n",
      "test playlists: 982\n",
      "\n",
      "total tracks in train playlists: 196250\n",
      "unique tracks in train playlists: 71782\n",
      "\n",
      "total tracks in test playlists: 36534\n",
      "total tracks in incomplete test playlists: 22919\n",
      "total incomplete test playlists: 975\n"
     ]
    }
   ],
   "source": [
    "all_playlist_ids = playlist_tracks_df.pid.unique()\n",
    "train_pids, test_pids = train_test_split(all_playlist_ids,random_state=0, test_size=0.20)\n",
    "print(f'total playlists: {len(all_playlist_ids)}')\n",
    "print(f'train playlists: {len(train_pids)}')\n",
    "print(f'test playlists: {len(test_pids)}')\n",
    "# 1. Get tracks that are only from the training playlists\n",
    "# 2. Get the track features(danceability,loudness) for each of these training tracks\n",
    "# 3. Make a test set that only includes tracks from the training set\n",
    "train_playlist_tracks_df = playlist_tracks_df.query('pid in @train_pids')\n",
    "\n",
    "# unique_train_tracks = train_playlist_tracks_df['tid'].unique()\n",
    "# train_cat_type = CategoricalDtype(categories=unique_train_tracks, ordered=True)\n",
    "# train_playlist_tracks_df.tid = train_playlist_tracks_df.tid.astype(train_cat_type)\n",
    "\n",
    "train_tracks_features_df = tracks_features_df.query('tid in @train_playlist_tracks_df.tid')\n",
    "test_playlist_tracks_df = playlist_tracks_df.query('pid in @test_pids and tid in @train_playlist_tracks_df.tid')\n",
    "print()\n",
    "print(f'total tracks in train playlists: {len(train_playlist_tracks_df)}')\n",
    "print(f'unique tracks in train playlists: {len(train_tracks_features_df)}')\n",
    "\n",
    "\n",
    "# 1. Get the first NUM_WITHHELD tracks for each playlist in test\n",
    "# 2. Get the track features for these with held tracks\n",
    "# 3. Compute mean features by grouping the tracks from incomplete playlists\n",
    "test_playlist_tracks_incomplete_df = test_playlist_tracks_df.groupby('pid').head(NUM_WITHHELD)\n",
    "# unique_test_tracks = test_playlist_tracks_incomplete_df['tid'].unique()\n",
    "# test_cat_type = CategoricalDtype(categories=unique_test_tracks, ordered=True)\n",
    "test_tracks_incomplete_features_df = test_playlist_tracks_incomplete_df.merge(tracks_features_df,how='inner',on='tid')\n",
    "# test_playlist_tracks_incomplete_df.tid = test_playlist_tracks_incomplete_df.tid.astype(test_cat_type)\n",
    "test_playlist_incomplete_features = test_tracks_incomplete_features_df[['pid',*SELECTED_TRACK_FEATURES]].groupby('pid',as_index=False).mean()\n",
    "print()\n",
    "print(f'total tracks in test playlists: {len(test_playlist_tracks_df)}')\n",
    "print(f'total tracks in incomplete test playlists: {len(test_playlist_tracks_incomplete_df)}')\n",
    "print(f'total incomplete test playlists: {len(test_playlist_incomplete_features)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN model that will find 25 nearest neighbors to the current playlist\n",
    "knn_clf = sklearn.neighbors.NearestNeighbors(n_neighbors=NUM_WITHHELD)\n",
    "knn_clf.fit(train_tracks_features_df[SELECTED_TRACK_FEATURES])\n",
    "distances, indices = knn_clf.kneighbors(test_playlist_incomplete_features[SELECTED_TRACK_FEATURES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each test playlist, get the 25 next nearest predicted tracks and add them to a table for evaluation\n",
    "def get_predicted_playlist_tracks():\n",
    "    for index, row in test_playlist_incomplete_features.iterrows():\n",
    "            predicted_tracks = train_tracks_features_df['tid'].iloc[indices[index]]\n",
    "            for pos, predicted_track in enumerate(predicted_tracks):\n",
    "                yield predicted_track, int(row['pid']),pos\n",
    "\n",
    "test_predicted_playlist_tracks_df = pd.DataFrame(get_predicted_playlist_tracks(), columns =['tid', 'pid', 'pos'])\n",
    "test_predicted_playlist_tracks_df.tid = test_predicted_playlist_tracks_df.tid.astype(cat_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluator:\n",
    "    def __init__(self,predicted_playlist_tracks,true_playlist_tracks):\n",
    "        self.predicted_playlist_tracks = predicted_playlist_tracks\n",
    "        self.true_playlist_tracks = true_playlist_tracks\n",
    "         \n",
    "\n",
    "    def evaluate(self):\n",
    "        predicted_playlist_tracks = self.predicted_playlist_tracks\n",
    "        true_playlist_tracks = self.true_playlist_tracks\n",
    "        \n",
    "        r_precision_list = []\n",
    "        ndcg_list = []\n",
    "        song_clicks_list =[]\n",
    "        \n",
    "        pid_list = true_playlist_tracks.pid.unique()\n",
    "        \n",
    "        def get_metrics():\n",
    "            for pid in tqdm(pid_list):\n",
    "                predictions = predicted_playlist_tracks.query('pid in @pid_list').tid.cat.codes\n",
    "                truth = true_playlist_tracks.query('pid in @pid_list').tid.cat.codes\n",
    "                yield (pid , self.r_precision(predictions,truth),self.ndcg(predictions,truth),self.song_clicks(predictions,truth))\n",
    "        metrics = pd.DataFrame(get_metrics(),columns=['pid','r_precision','ndcg','songs_click'])\n",
    "        return metrics[['r_precision','ndcg','songs_click']].mean()\n",
    "         \n",
    "    def r_precision(self,predictions,truth,n_tracks = N_NEIGHBORS):\n",
    "        truth_set = set(truth)\n",
    "        prediction_set = set(predictions[:n_tracks])\n",
    "        intersect = prediction_set.intersection(truth_set)\n",
    "        return float(len(intersect)) / len(truth_set)\n",
    "            \n",
    "        \n",
    "    def ndcg(self,predictions,truth,n_tracks = N_NEIGHBORS):\n",
    "        predictions = list(predictions[:n_tracks])\n",
    "        truth = list(truth)\n",
    "        \n",
    "        score = [float(element in truth) for element in predictions]    \n",
    "        dcg  = np.sum(score / np.log2(1 + np.arange(1, len(score) + 1)))\n",
    "        \n",
    "        ones = np.ones([1,len(truth)])\n",
    "        idcg = np.sum(ones / np.log2(1 + np.arange(1, len(truth) + 1)))\n",
    "    \n",
    "        return (dcg / idcg)\n",
    "    \n",
    "    \n",
    "    def song_clicks(self,predictions,truth,n_tracks = N_NEIGHBORS):\n",
    "        predictions = predictions[:n_tracks]\n",
    "        \n",
    "        i = set(predictions).intersection(set(truth))\n",
    "        \n",
    "        for index, t in enumerate(predictions):\n",
    "            for track in i:\n",
    "                if t == track:\n",
    "                    return float(int(index / 10))\n",
    "                \n",
    "        return float(n_tracks / 10.0 + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 975/975 [00:28<00:00, 33.85it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "r_precision    0.000389\n",
       "ndcg           0.000985\n",
       "songs_click    0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_eval = Evaluator(test_predicted_playlist_tracks_df,test_playlist_tracks_df)\n",
    "model_eval.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network (NeuMF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import dok_matrix\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_playlist_tracks_df['cat_codes'] = train_playlist_tracks_df['tid'].cat.codes # Add a new column for integral values\n",
    "# unique_train_tracks = train_playlist_tracks_df['cat_codes']\n",
    "# test_playlist_tracks_incomplete_df['cat_codes'] = test_playlist_tracks_incomplete_df['tid'].cat.codes # Add a new column for integral values\n",
    "# unique_test_tracks = test_playlist_tracks_incomplete_df['cat_codes']\n",
    "\n",
    "total_playlist_tracks_df = train_playlist_tracks_df.append(test_playlist_tracks_incomplete_df)\n",
    "unique_tracks = total_playlist_tracks_df['tid'].unique()\n",
    "total_cat_type = CategoricalDtype(categories=unique_tracks, ordered=True)\n",
    "total_playlist_tracks_df.tid = train_playlist_tracks_df.tid.astype(total_cat_type)\n",
    "total_playlist_tracks_df['cat_codes'] = total_playlist_tracks_df['tid'].cat.codes\n",
    "\n",
    "dok_mat_n_rows = total_playlist_tracks_df.shape[0]\n",
    "dok_mat_n_cols = len(unique_tracks)\n",
    "\n",
    "dok_mat_rows = total_playlist_tracks_df['pid']\n",
    "dok_mat_cols = total_playlist_tracks_df['cat_codes']\n",
    "\n",
    "# Make a dictionary key sparse matrix\n",
    "dok_mat = dok_matrix((dok_mat_n_rows, dok_mat_n_cols))\n",
    "\n",
    "# TODO vectorize later if possible\n",
    "for (pid, cat_code) in tqdm(zip(dok_mat_rows, dok_mat_cols)):\n",
    "    dok_mat[pid, cat_code] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "embedding_dim = 8\n",
    "num_epochs = 2\n",
    "learning_rate = 0.001\n",
    "batch_size = 256\n",
    "rand_negative_fill_in = 4\n",
    "layer_sizes = [64, 32, 16, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralMF(torch.nn.Module):\n",
    "    def __init__(self, num_pl, num_tr, dim):\n",
    "        super(NeuralMF, self).__init__()\n",
    "        num_of_layers = len(layer_sizes)\n",
    "            \n",
    "        self.pl_embedding = torch.nn.Embedding(num_pl, dim, sparse=True)\n",
    "        self.tr_embedding = torch.nn.Embedding(num_tr, dim, sparse=True)\n",
    "        \n",
    "        self.pl_mlp_embedding = torch.nn.Embedding(num_pl, layer_sizes[0] // 2)\n",
    "        self.tr_mlp_embedding = torch.nn.Embedding(num_tr, layer_sizes[0] // 2)\n",
    "        \n",
    "        def lecunn_uniform(layer):\n",
    "            fan_in, fan_out = layer.in_features, layer.out_features\n",
    "            limit = np.sqrt(3. / fan_in)\n",
    "            layer.weight.data.uniform_(-limit, limit)\n",
    "        def glorot_uniform(layer):\n",
    "            fan_in, fan_out = layer.in_features, layer.out_features\n",
    "            limit = np.sqrt(6. / (fan_in + fan_out))\n",
    "            layer.weight.data.uniform_(-limit, limit)\n",
    "            \n",
    "        self.mlp = torch.nn.ModuleList()\n",
    "        for i in range(1, num_of_layers):\n",
    "            self.mlp.extend([torch.nn.Linear(layer_sizes[i - 1], layer_sizes[i])])\n",
    "        for layer in self.mlp:\n",
    "            glorot_uniform(layer)\n",
    "\n",
    "        self.final = torch.nn.Linear(dim + layer_sizes[-1], 1)\n",
    "        lecunn_uniform(self.final)\n",
    "\n",
    "    def forward(self, playlists, tracks):\n",
    "        pl_vec = self.pl_embedding(playlists)\n",
    "        tr_vec = self.tr_embedding(tracks)\n",
    "        prod = pl_vec*tr_vec\n",
    "        \n",
    "        pl_mlp_vec = self.pl_mlp_embedding(playlists)\n",
    "        tr_mlp_vec = self.tr_mlp_embedding(tracks)\n",
    "        \n",
    "        mlp_vec = torch.cat([pl_mlp_vec, tr_mlp_vec], dim=-1)\n",
    "        \n",
    "        for i, layer in enumerate(self.mlp):\n",
    "            mlp_vec = layer(mlp_vec)\n",
    "            mlp_vec = torch.nn.functional.relu(mlp_vec)\n",
    "            \n",
    "        result = self.final(torch.cat([prod,mlp_vec], dim=-1))\n",
    "        activated_result = torch.flatten(torch.sigmoid(result))\n",
    "        return activated_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseDenseOptimizer:\n",
    "    def __init__(self, *op):\n",
    "        self.optimizers = op\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for op in self.optimizers:\n",
    "            op.zero_grad()\n",
    "\n",
    "    def step(self):\n",
    "        for op in self.optimizers:\n",
    "            op.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralMF(dok_mat.shape[0], dok_mat.shape[1], embedding_dim)\n",
    "\n",
    "dense_weights_to_optimize = [weight_tensor for (param_name, weight_tensor) in list(model.named_parameters()) if param_name not in ('pl_embedding.weight','tr_embedding.weight')]\n",
    "sparse_weights_to_optimize = [model.pl_embedding.weight,model.tr_embedding.weight]\n",
    "sparse_optim = torch.optim.SparseAdam(sparse_weights_to_optimize, lr=learning_rate)\n",
    "dense_optim = torch.optim.Adam(dense_weights_to_optimize, lr=learning_rate)\n",
    "optim = SparseDenseOptimizer(sparse_optim, dense_optim)\n",
    "\n",
    "assert len(dense_weights_to_optimize + sparse_weights_to_optimize) == len(list(model.parameters()))\n",
    "\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "def make_train_data():\n",
    "    pl_input, tr_input, recs = [], [], []\n",
    "    for (pl, tr) in dok_mat.keys():\n",
    "        yield pl, tr, 1.0\n",
    "        for t in range(rand_negative_fill_in):\n",
    "            rand_num = np.random.randint(dok_mat.shape[1])\n",
    "            while(pl, rand_num) in dok_mat.keys():\n",
    "                rand_num = np.random.randint(dok_mat.shape[1])\n",
    "            yield pl, rand_num, 0.0\n",
    "\n",
    "def train_loop(data_loader):\n",
    "    for epoch in range(num_epochs):\n",
    "        for pl, tr, recs in data_loader:\n",
    "            optim.zero_grad()\n",
    "            out = model(pl, tr)\n",
    "            loss = loss_fn(out, recs)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "        print(f'training loss after epoch-{epoch+1} = {(loss.item()*100):.4f}%')\n",
    "\n",
    "def run_training():\n",
    "    data_loader = torch.utils.data.DataLoader(list(make_train_data()), batch_size=batch_size)\n",
    "    train_loop(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_training()\n",
    "torch.save(model.state_dict(), MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralMF(dok_mat.shape[0], dok_mat.shape[1], embedding_dim)\n",
    "model.load_state_dict(torch.load(MODEL_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to make recommendations\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "playlist_for_test = np.random.choice(test_pids)\n",
    "ground_truth = test_playlist_tracks_df[test_playlist_tracks_df['pid'] == playlist_for_test]\n",
    "playlist_seeds = test_playlist_tracks_incomplete_df[test_playlist_tracks_incomplete_df['pid'] == playlist_for_test]\n",
    "\n",
    "assert len(playlist_seeds) < len(ground_truth)\n",
    "\n",
    "playlist_embedding_weight_matrix = model.pl_mlp_embedding.weight\n",
    "chosen_playlist_vector = playlist_embedding_weight_matrix[playlist_for_test]\n",
    "km_model = KMeans(n_clusters=100, random_state=0, verbose=0).fit(playlist_embedding_weight_matrix.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_vector = chosen_playlist_vector.detach().numpy().reshape(1,-1)\n",
    "playlist_predictor = km_model.predict(chosen_vector)\n",
    "playlist_labels = km_model.labels_\n",
    "neighbors = []\n",
    "for pid, playlist_label in enumerate(playlist_labels):\n",
    "    if playlist_label == playlist_predictor:\n",
    "        neighbors.append(pid)\n",
    "print(f'other playlists in cluster: {len(neighbors)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = []\n",
    "for pid in neighbors:\n",
    "    tracks += list(total_playlist_tracks_df[total_playlist_tracks_df['pid'] == int(pid)]['tid'].cat.codes)\n",
    "tracks = [tid for tid in tracks if tid > 0]\n",
    "print(f'other tracks from neighbors in cluster: {len(tracks)}') \n",
    "\n",
    "pids_pred = torch.tensor(np.full(len(tracks), playlist_for_test, dtype='int32'))\n",
    "tracks_pred = torch.tensor(np.array(tracks, dtype='int32'))\n",
    "\n",
    "print('\\nRanking most likely tracks using the NeuMF model...')\n",
    "# and predict tracks for my user\n",
    "results = model(pids_pred, tracks_pred)\n",
    "results = results.tolist()\n",
    "print('Ranked the tracks!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(np.nan, index=range(len(results)), columns=['probability', *list(tracks_features_df.columns)])\n",
    "\n",
    "for i, probability in enumerate(results):\n",
    "    tid = total_playlist_tracks_df[total_playlist_tracks_df['cat_codes'] == i].iloc[0]['tid']\n",
    "    other_features = tracks_features_df[tracks_features_df['tid'] == tid]\n",
    "    val = [probability, *other_features.values.tolist()[0]]\n",
    "    results_df.loc[i] = val\n",
    "results_df = results_df.sort_values(by=['probability'], ascending=False)\n",
    "\n",
    "results_df.head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
