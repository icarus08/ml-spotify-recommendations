{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import sklearn\n",
    "import sklearn.neighbors\n",
    "from pathlib import Path\n",
    "from pandas.api.types import CategoricalDtype\n",
    "from operator import itemgetter\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# constants\n",
    "RAW_DATA_PATH = Path('raw_data/')\n",
    "DATAFRAME_PATH = Path('dataframes/')\n",
    "MODEL_PATH = Path('model/state_dict_model.pt')\n",
    "TOTAL_TRACKS = 50\n",
    "NUM_WITHHELD = 25\n",
    "SELECTED_TRACK_FEATURES = ['danceability', 'energy', 'key', 'loudness',\n",
    "                     'speechiness', 'acousticness', 'instrumentalness',\n",
    "                     'liveness', 'valence', 'tempo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tid</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spotify:track:3uvsVUrAaGQJCTEUR1S3Sx</td>\n",
       "      <td>0.523</td>\n",
       "      <td>0.422</td>\n",
       "      <td>3</td>\n",
       "      <td>-10.385</td>\n",
       "      <td>0.0270</td>\n",
       "      <td>0.78300</td>\n",
       "      <td>0.005140</td>\n",
       "      <td>0.0898</td>\n",
       "      <td>0.145</td>\n",
       "      <td>129.876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spotify:track:0heE5tAAaDQmnGhVDImPl2</td>\n",
       "      <td>0.493</td>\n",
       "      <td>0.594</td>\n",
       "      <td>8</td>\n",
       "      <td>-4.404</td>\n",
       "      <td>0.0378</td>\n",
       "      <td>0.25600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0759</td>\n",
       "      <td>0.304</td>\n",
       "      <td>123.751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spotify:track:3omXshBamrREltcf24gYDC</td>\n",
       "      <td>0.468</td>\n",
       "      <td>0.692</td>\n",
       "      <td>2</td>\n",
       "      <td>-4.015</td>\n",
       "      <td>0.0295</td>\n",
       "      <td>0.02020</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.5230</td>\n",
       "      <td>0.561</td>\n",
       "      <td>78.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spotify:track:6TYWE19e35N7Bn5heHwyY6</td>\n",
       "      <td>0.553</td>\n",
       "      <td>0.564</td>\n",
       "      <td>9</td>\n",
       "      <td>-7.072</td>\n",
       "      <td>0.0418</td>\n",
       "      <td>0.03900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3180</td>\n",
       "      <td>0.310</td>\n",
       "      <td>149.953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spotify:track:1xznGGDReH1oQq0xzbwXa3</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.619</td>\n",
       "      <td>1</td>\n",
       "      <td>-5.886</td>\n",
       "      <td>0.0532</td>\n",
       "      <td>0.00784</td>\n",
       "      <td>0.004230</td>\n",
       "      <td>0.3510</td>\n",
       "      <td>0.371</td>\n",
       "      <td>103.989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    tid  danceability  energy  key  loudness  \\\n",
       "0  spotify:track:3uvsVUrAaGQJCTEUR1S3Sx         0.523   0.422    3   -10.385   \n",
       "1  spotify:track:0heE5tAAaDQmnGhVDImPl2         0.493   0.594    8    -4.404   \n",
       "2  spotify:track:3omXshBamrREltcf24gYDC         0.468   0.692    2    -4.015   \n",
       "3  spotify:track:6TYWE19e35N7Bn5heHwyY6         0.553   0.564    9    -7.072   \n",
       "4  spotify:track:1xznGGDReH1oQq0xzbwXa3         0.791   0.619    1    -5.886   \n",
       "\n",
       "   speechiness  acousticness  instrumentalness  liveness  valence    tempo  \n",
       "0       0.0270       0.78300          0.005140    0.0898    0.145  129.876  \n",
       "1       0.0378       0.25600          0.000000    0.0759    0.304  123.751  \n",
       "2       0.0295       0.02020          0.000002    0.5230    0.561   78.009  \n",
       "3       0.0418       0.03900          0.000000    0.3180    0.310  149.953  \n",
       "4       0.0532       0.00784          0.004230    0.3510    0.371  103.989  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read tracks.h5 which contains tracks with features like danceability, loudness ,... etc\n",
    "# set type of track_uri to category, to convert string to an int unique id\n",
    "# rename track_uri to tid and sort values based on tid\n",
    "tracks_features_df = pd.read_hdf(DATAFRAME_PATH / 'tracks.h5', 'tracks')\n",
    "cat_type = CategoricalDtype(categories=tracks_features_df.track_uri, ordered=True)\n",
    "tracks_features_df.track_uri = tracks_features_df.track_uri.astype(cat_type)\n",
    "tracks_features_df = tracks_features_df.rename(columns={'track_uri':'tid'})\n",
    "tracks_features_df = tracks_features_df[['tid',*SELECTED_TRACK_FEATURES]].sort_values('tid').reset_index(drop=True)\n",
    "tracks_features_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:02<00:00,  5.03it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tid</th>\n",
       "      <th>pid</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spotify:track:3uvsVUrAaGQJCTEUR1S3Sx</td>\n",
       "      <td>7000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spotify:track:0heE5tAAaDQmnGhVDImPl2</td>\n",
       "      <td>7000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spotify:track:3omXshBamrREltcf24gYDC</td>\n",
       "      <td>7000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spotify:track:6TYWE19e35N7Bn5heHwyY6</td>\n",
       "      <td>7000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spotify:track:1xznGGDReH1oQq0xzbwXa3</td>\n",
       "      <td>7000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    tid   pid  pos\n",
       "0  spotify:track:3uvsVUrAaGQJCTEUR1S3Sx  7000    0\n",
       "1  spotify:track:0heE5tAAaDQmnGhVDImPl2  7000    1\n",
       "2  spotify:track:3omXshBamrREltcf24gYDC  7000    2\n",
       "3  spotify:track:6TYWE19e35N7Bn5heHwyY6  7000    3\n",
       "4  spotify:track:1xznGGDReH1oQq0xzbwXa3  7000    4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read 10000 playlists from the official spoitfy 1M playlists\n",
    "# for each playlist, get the tracks and their positions\n",
    "def make_playlist_dfs(path):\n",
    "    playlists = []\n",
    "    playlist_tracks = []\n",
    "    for file in tqdm(os.listdir(path)):\n",
    "        if not file.endswith(\".json\"):\n",
    "            continue\n",
    "        with open(path/file) as f:\n",
    "            js_slice = json.load(f)\n",
    "            for playlist in js_slice['playlists']:\n",
    "                if playlist['num_tracks'] > TOTAL_TRACKS:\n",
    "                    sorted_tracks = sorted(playlist['tracks'], key=itemgetter('pos')) \n",
    "                    for track in sorted_tracks[:TOTAL_TRACKS]:\n",
    "                        yield track['track_uri'], playlist['pid'], track['pos']\n",
    "\n",
    "playlist_tracks_df = pd.DataFrame(make_playlist_dfs(RAW_DATA_PATH),columns=['tid','pid','pos'])\n",
    "playlist_tracks_df.tid = playlist_tracks_df.tid.astype(cat_type)\n",
    "playlist_tracks_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total playlists: 4907\n",
      "train playlists: 3925\n",
      "test playlists: 982\n",
      "\n",
      "total tracks in train playlists: 196250\n",
      "unique tracks in train playlists: 71782\n",
      "\n",
      "total tracks in test playlists: 36534\n",
      "total tracks in incomplete test playlists: 22919\n",
      "total incomplete test playlists: 975\n"
     ]
    }
   ],
   "source": [
    "all_playlist_ids = playlist_tracks_df.pid.unique()\n",
    "train_pids, test_pids = train_test_split(all_playlist_ids,random_state=0, test_size=0.20)\n",
    "print(f'total playlists: {len(all_playlist_ids)}')\n",
    "print(f'train playlists: {len(train_pids)}')\n",
    "print(f'test playlists: {len(test_pids)}')\n",
    "# 1. Get tracks that are only from the training playlists\n",
    "# 2. Get the track features(danceability,loudness) for each of these training tracks\n",
    "# 3. Make a test set that only includes tracks from the training set\n",
    "train_playlist_tracks_df = playlist_tracks_df.query('pid in @train_pids')\n",
    "\n",
    "unique_train_tracks = train_playlist_tracks_df['tid'].unique()\n",
    "train_cat_type = CategoricalDtype(categories=unique_train_tracks, ordered=True)\n",
    "train_playlist_tracks_df.tid = train_playlist_tracks_df.tid.astype(train_cat_type)\n",
    "\n",
    "train_tracks_features_df = tracks_features_df.query('tid in @train_playlist_tracks_df.tid')\n",
    "test_playlist_tracks_df = playlist_tracks_df.query('pid in @test_pids and tid in @train_playlist_tracks_df.tid')\n",
    "print()\n",
    "print(f'total tracks in train playlists: {len(train_playlist_tracks_df)}')\n",
    "print(f'unique tracks in train playlists: {len(train_tracks_features_df)}')\n",
    "\n",
    "\n",
    "# 1. Get the first NUM_WITHHELD tracks for each playlist in test\n",
    "# 2. Get the track features for these with held tracks\n",
    "# 3. Compute mean features by grouping the tracks from incomplete playlists\n",
    "test_playlist_tracks_incomplete_df = test_playlist_tracks_df.groupby('pid').head(NUM_WITHHELD)\n",
    "test_tracks_incomplete_features_df = test_playlist_tracks_incomplete_df.merge(tracks_features_df,how='inner',on='tid')\n",
    "test_playlist_incomplete_features = test_tracks_incomplete_features_df[['pid',*SELECTED_TRACK_FEATURES]].groupby('pid',as_index=False).mean()\n",
    "print()\n",
    "print(f'total tracks in test playlists: {len(test_playlist_tracks_df)}')\n",
    "print(f'total tracks in incomplete test playlists: {len(test_playlist_tracks_incomplete_df)}')\n",
    "print(f'total incomplete test playlists: {len(test_playlist_incomplete_features)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN model that will find 25 nearest neighbors to the current playlist\n",
    "knn_clf = sklearn.neighbors.NearestNeighbors(n_neighbors=NUM_WITHHELD)\n",
    "knn_clf.fit(train_tracks_features_df[SELECTED_TRACK_FEATURES])\n",
    "distances, indices = knn_clf.kneighbors(test_playlist_incomplete_features[SELECTED_TRACK_FEATURES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tid</th>\n",
       "      <th>pid</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spotify:track:0lCG1ndJE7vsNrpWgTv17L</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spotify:track:1U37ItHkYDpKMVvoIPcxGc</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spotify:track:3LSN1ZAbeXmYWyq4O1jRGM</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spotify:track:03HpzzH36FRs8zYONAwFJb</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spotify:track:6QBkPN3ARmAFVtVAk7oYN9</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24370</th>\n",
       "      <td>spotify:track:6eHhubs2FeAVjWkSRRMLRS</td>\n",
       "      <td>9973</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24371</th>\n",
       "      <td>spotify:track:6808fuj56HYDOND2CpyqsT</td>\n",
       "      <td>9973</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24372</th>\n",
       "      <td>spotify:track:1K0VI2vWPR85jvGeeWPIjD</td>\n",
       "      <td>9973</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24373</th>\n",
       "      <td>spotify:track:6khitcV9375KZ5hZRrSiL0</td>\n",
       "      <td>9973</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24374</th>\n",
       "      <td>spotify:track:1w5sLDYzYAGI0AkLc6FPlO</td>\n",
       "      <td>9973</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24375 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        tid   pid  pos\n",
       "0      spotify:track:0lCG1ndJE7vsNrpWgTv17L     0    0\n",
       "1      spotify:track:1U37ItHkYDpKMVvoIPcxGc     0    1\n",
       "2      spotify:track:3LSN1ZAbeXmYWyq4O1jRGM     0    2\n",
       "3      spotify:track:03HpzzH36FRs8zYONAwFJb     0    3\n",
       "4      spotify:track:6QBkPN3ARmAFVtVAk7oYN9     0    4\n",
       "...                                     ...   ...  ...\n",
       "24370  spotify:track:6eHhubs2FeAVjWkSRRMLRS  9973   20\n",
       "24371  spotify:track:6808fuj56HYDOND2CpyqsT  9973   21\n",
       "24372  spotify:track:1K0VI2vWPR85jvGeeWPIjD  9973   22\n",
       "24373  spotify:track:6khitcV9375KZ5hZRrSiL0  9973   23\n",
       "24374  spotify:track:1w5sLDYzYAGI0AkLc6FPlO  9973   24\n",
       "\n",
       "[24375 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for each test playlist, get the 25 next nearest predicted tracks and add them to a table for evaluation\n",
    "def get_predicted_playlist_tracks():\n",
    "    for index, row in test_playlist_incomplete_features.iterrows():\n",
    "            predicted_tracks = train_tracks_features_df['tid'].iloc[indices[index]]\n",
    "            for pos, predicted_track in enumerate(predicted_tracks):\n",
    "                yield predicted_track, int(row['pid']),pos\n",
    "\n",
    "test_predicted_playlist_tracks_df = pd.DataFrame(get_predicted_playlist_tracks(), columns =['tid', 'pid', 'pos'])\n",
    "test_predicted_playlist_tracks_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network (NeuMF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import dok_matrix\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "196250it [00:02, 76179.60it/s]\n"
     ]
    }
   ],
   "source": [
    "train_playlist_tracks_df['cat_codes'] = train_playlist_tracks_df['tid'].cat.codes # Add a new column for integral values\n",
    "unique_train_tracks = train_playlist_tracks_df['cat_codes']\n",
    "\n",
    "# Make a dictionary key sparse matrix\n",
    "dok_mat = dok_matrix((train_playlist_tracks_df.shape[0], len(unique_train_tracks)))\n",
    "\n",
    "# TODO vectorize later if possible\n",
    "for (pid, cat_code) in tqdm(zip(train_playlist_tracks_df['pid'], train_playlist_tracks_df['cat_codes'])):\n",
    "    dok_mat[pid, cat_code] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "embedding_dim = 8\n",
    "num_epochs = 2\n",
    "learning_rate = 0.001\n",
    "batch_size = 256\n",
    "rand_negative_fill_in = 4\n",
    "layer_sizes = [64, 32, 16, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralMF(torch.nn.Module):\n",
    "    def __init__(self, num_pl, num_tr, dim):\n",
    "        super(NeuralMF, self).__init__()\n",
    "        num_of_layers = len(layer_sizes)\n",
    "            \n",
    "        self.pl_embedding = torch.nn.Embedding(num_pl, dim, sparse=True)\n",
    "        self.tr_embedding = torch.nn.Embedding(num_tr, dim, sparse=True)\n",
    "        \n",
    "        self.pl_mlp_embedding = torch.nn.Embedding(num_pl, layer_sizes[0] // 2)\n",
    "        self.tr_mlp_embedding = torch.nn.Embedding(num_tr, layer_sizes[0] // 2)\n",
    "        \n",
    "        def lecunn_uniform(layer):\n",
    "            fan_in, fan_out = layer.in_features, layer.out_features\n",
    "            limit = np.sqrt(3. / fan_in)\n",
    "            layer.weight.data.uniform_(-limit, limit)\n",
    "        def glorot_uniform(layer):\n",
    "            fan_in, fan_out = layer.in_features, layer.out_features\n",
    "            limit = np.sqrt(6. / (fan_in + fan_out))\n",
    "            layer.weight.data.uniform_(-limit, limit)\n",
    "            \n",
    "        self.mlp = torch.nn.ModuleList()\n",
    "        for i in range(1, num_of_layers):\n",
    "            self.mlp.extend([torch.nn.Linear(layer_sizes[i - 1], layer_sizes[i])])\n",
    "        for layer in self.mlp:\n",
    "            glorot_uniform(layer)\n",
    "\n",
    "        self.final = torch.nn.Linear(dim + layer_sizes[-1], 1)\n",
    "        lecunn_uniform(self.final)\n",
    "\n",
    "    def forward(self, playlists, tracks):\n",
    "        pl_vec = self.pl_embedding(playlists)\n",
    "        tr_vec = self.tr_embedding(tracks)\n",
    "        prod = pl_vec*tr_vec\n",
    "        \n",
    "        pl_mlp_vec = self.pl_mlp_embedding(playlists)\n",
    "        tr_mlp_vec = self.tr_mlp_embedding(tracks)\n",
    "        \n",
    "        mlp_vec = torch.cat([pl_mlp_vec, tr_mlp_vec], dim=-1)\n",
    "        \n",
    "        for i, layer in enumerate(self.mlp):\n",
    "            mlp_vec = layer(mlp_vec)\n",
    "            mlp_vec = torch.nn.functional.relu(mlp_vec)\n",
    "            \n",
    "        result = self.final(torch.cat([prod,mlp_vec], dim=-1))\n",
    "        activated_result = torch.flatten(torch.sigmoid(result))\n",
    "        return activated_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseDenseOptimizer:\n",
    "    def __init__(self, *op):\n",
    "        self.optimizers = op\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for op in self.optimizers:\n",
    "            op.zero_grad()\n",
    "\n",
    "    def step(self):\n",
    "        for op in self.optimizers:\n",
    "            op.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralMF(dok_mat.shape[0], dok_mat.shape[1], embedding_dim)\n",
    "\n",
    "dense_weights_to_optimize = [weight_tensor for (param_name, weight_tensor) in list(model.named_parameters()) if param_name not in ('pl_embedding.weight','tr_embedding.weight')]\n",
    "sparse_weights_to_optimize = [model.pl_embedding.weight,model.tr_embedding.weight]\n",
    "sparse_optim = torch.optim.SparseAdam(sparse_weights_to_optimize, lr=learning_rate)\n",
    "dense_optim = torch.optim.Adam(dense_weights_to_optimize, lr=learning_rate)\n",
    "optim = SparseDenseOptimizer(sparse_optim, dense_optim)\n",
    "\n",
    "assert len(dense_weights_to_optimize + sparse_weights_to_optimize) == len(list(model.parameters()))\n",
    "\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "def make_train_data():\n",
    "    pl_input, tr_input, recs = [], [], []\n",
    "    for (pl, tr) in dok_mat.keys():\n",
    "        yield pl, tr, 1.0\n",
    "        for t in range(rand_negative_fill_in):\n",
    "            rand_num = np.random.randint(dok_mat.shape[1])\n",
    "            while(pl, rand_num) in dok_mat.keys():\n",
    "                rand_num = np.random.randint(dok_mat.shape[1])\n",
    "            yield pl, rand_num, 0.0\n",
    "\n",
    "def train_loop(data_loader):\n",
    "    for epoch in range(num_epochs):\n",
    "        for pl, tr, recs in data_loader:\n",
    "            optim.zero_grad()\n",
    "            out = model(pl, tr)\n",
    "            loss = loss_fn(out, recs)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "        print(f'training loss after epoch-{epoch+1} = {(loss.item()*100):.4f}%')\n",
    "\n",
    "def run_training():\n",
    "    data_loader = torch.utils.data.DataLoader(list(make_train_data()), batch_size=batch_size)\n",
    "    train_loop(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss after epoch-1 = 69.3148%\n",
      "training loss after epoch-2 = 69.3147%\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'MODEL_PATH' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-f725308e8028>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrun_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMODEL_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'MODEL_PATH' is not defined"
     ]
    }
   ],
   "source": [
    "run_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(model.state_dict(), MODEL_PATH)\n",
    "model = NeuralMF(dok_mat.shape[0], dok_mat.shape[1], embedding_dim)\n",
    "model.load_state_dict(torch.load(MODEL_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to make recommendations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
